{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_optflow2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import pdb\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VidNet(nn.Module):\n",
    "    def __init__(self,method,num_classes,input_features,classifier_size,timesteps_vid,optical_flow):\n",
    "        super(VidNet, self).__init__()\n",
    "#         self.num_timesteps = num_timesteps\n",
    "        self.optical_flow = optical_flow\n",
    "        self.timesteps_vid = timesteps_vid\n",
    "        self.hidden_dim = 100\n",
    "        self.method = method\n",
    "        self.num_classes = num_classes\n",
    "        self.input_features = input_features\n",
    "        self.classifier_size = classifier_size\n",
    "        if self.optical_flow:\n",
    "            self.hidden = self.init_hidden()\n",
    "        if self.method=='slow':\n",
    "            self.mult1 = (self.timesteps_vid//4)//2\n",
    "            self.mult2 = 2\n",
    "        else:\n",
    "            self.mult1 = 1\n",
    "            self.mult2 = 1\n",
    "        self.rnn = nn.RNN(12,self.hidden_dim,2,batch_first=True)\n",
    "        self.layers = nn.Sequential(\n",
    "            # in, out, stride, padding\n",
    "            # in, out, stride, padding\n",
    "            nn.Conv2d(self.input_features,96,11,stride = 3,padding = 2),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout(.25),\n",
    "            nn.Conv2d(96*self.mult1,256,5,stride = 1,padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout(.25),\n",
    "            nn.Conv2d(256*self.mult2,384*self.mult2,3,stride = 1,padding=2),\n",
    "            nn.Conv2d(384*self.mult2,384,3,stride = 1,padding=2),\n",
    "            nn.Conv2d(384,256,3,stride = 1,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3,2))\n",
    "        self.classifiers =nn.Sequential(\n",
    "            nn.Linear(9216*self.classifier_size + self.timesteps_vid*self.hidden_dim,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,self.num_classes)\n",
    "#             nn.Softmax() # maybe make delete this and try F.log_softmax() in forward\n",
    "            )\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        # self.hidden = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
    "        self.hidden =  torch.zeros(2, 10, self.hidden_dim)\n",
    "\n",
    "    def forward(self,inputs,optflow_in):\n",
    "        if self.method == 'single' or self.method =='early' or self.method == 'conv_pool':\n",
    "            x = inputs\n",
    "            for layer in self.layers:\n",
    "                x = layer(x)\n",
    "\n",
    "        elif self.method == 'late':\n",
    "            x = torch.Tensor(0,0)\n",
    "            for xind in range(inputs.size(1)):\n",
    "\n",
    "                xin = inputs[:,xind,:,:].unsqueeze(1)\n",
    "\n",
    "            # x1,x2 = input\n",
    "                for layer in self.layers:\n",
    "                    xin = layer(xin)\n",
    "                x = torch.cat((x,xin),1).cuda()\n",
    "\n",
    "        elif self.method == 'slow':\n",
    "            x = torch.Tensor(0,0).cuda()\n",
    "            xout = torch.Tensor(0,0).cuda()\n",
    "            for xind in np.arange(0,inputs.size(1),4):\n",
    "                xin = inputs[:,xind:xind+4,:,:]\n",
    "            # x1,x2,x3,x4 = input\n",
    "                for layer in self.layers[0:5]:\n",
    "                    xin = layer(xin)\n",
    "                xout = torch.cat((xout,xin),1)\n",
    "            xa = xout[:,:int(xout.shape[1]/2),:,:]\n",
    "            xb = xout[:,int(xout.shape[1]/2):,:,:]\n",
    "            for layer in self.layers[5:10]:\n",
    "                xa = layer(xa)\n",
    "                xb = layer(xb)\n",
    "            x = torch.cat((xa,xb),1)\n",
    "            for layer in self.layers[10:]:\n",
    "                x = layer(x)\n",
    "\n",
    "        else:\n",
    "            print('Define Method')\n",
    "            x = inputs\n",
    "#             break\n",
    "\n",
    "        x = x.view(x.size(0),-1)\n",
    "        if self.optical_flow:\n",
    "            output, self.hidden = self.rnn(optflow_in,self.hidden)\n",
    "            rnn_out = output.contiguous().view(output.size(0),-1)\n",
    "            x = torch.cat((x,rnn_out),1)\n",
    "        for classifier in self.classifiers:\n",
    "            x = classifier(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,net,dic,datapath,timesteps,epochs,\n",
    "                 optimizer,criterion,batch_size,color,random_sample, skip,\n",
    "                 optical_flow):\n",
    "        self.dic = dic\n",
    "        self.datapath = datapath\n",
    "        self.optical_flow = optical_flow\n",
    "        self.method = method\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.timesteps = timesteps\n",
    "        self.net = net\n",
    "        self.batch_size = batch_size\n",
    "        self.color = color\n",
    "        self.random_sample = random_sample\n",
    "        self.skip = skip\n",
    "        self.rng = np.random.RandomState(123456)\n",
    "        self.proj = self.rng.randn(12,2*110*110).astype(np.float32)\n",
    "\n",
    "    def get_accuracy(self,outputs,labels):\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = float(((predicted == labels.detach()).sum()).item())\n",
    "        total = labels.size(0)\n",
    "        return correct, total\n",
    "\n",
    "    def train_test(self,path,train):\n",
    "        loss_vec = []\n",
    "        acc_vec = []\n",
    "        # net = VidNet(self.timesteps,self.method)\n",
    "#         content_t = []\n",
    "        paths = os.listdir(path)\n",
    "        paths = [path[2:] for path in paths if path[0]=='.']\n",
    "        pt_test = paths[::4]\n",
    "        pt_train = list(set(paths) - set(pt_test))\n",
    "        if train:\n",
    "            paths = pt_train\n",
    "        else:\n",
    "            paths = pt_test\n",
    "#         random.shuffle(paths)\n",
    "        labels = [re.findall('_([^_]*)_', datastr)[0] for datastr in paths]\n",
    "#         x = list(set(labels))\n",
    "        self.dic = dict(zip(x, list(range(0,len(x)))))\n",
    "        num_labels = [dic[v] for v in labels]\n",
    "\n",
    "#         paths = [re.findall('\"([^\"]*)\"', c)[0] for c in content_t]\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for bs in range(self.batch_size):\n",
    "            b_targets = num_labels[bs*self.batch_size:(bs*self.batch_size)+self.batch_size]\n",
    "            b_path = paths[bs*self.batch_size:(bs*self.batch_size)+self.batch_size]\n",
    "            frame_array=[]\n",
    "            # import pdb; pdb.set_trace()\n",
    "            flpts_array = []\n",
    "            for vid_name in b_path:\n",
    "#                 if vid_name[0]=='.':\n",
    "#                     vid_name = vid_name[2:]\n",
    "                if self.optical_flow:\n",
    "                    try:\n",
    "                        frame, flpts = video3d(self.datapath + vid_name, (110,110,self.timesteps),\n",
    "                                            color=self.color,skip=self.skip,rand=self.random_sample,\n",
    "                                            optical_flow=self.optical_flow,proj = self.proj)\n",
    "                    except:\n",
    "                        import pdb; pdb.set_trace()\n",
    "                    frame = torch.Tensor(np.array(frame))\n",
    "                    # (x_new,y_new),(x_old,y_old)  N x 2, N x 2\n",
    "                    # new = flpts[0][0]\n",
    "\n",
    "                    flpts = np.array(flpts)\n",
    "                else:\n",
    "                    frame = torch.Tensor(np.array(video3d(self.datapath + vid_name,\n",
    "                                                                     (110,110,self.timesteps),color=self.color,\n",
    "                                                                     skip=self.skip,rand=self.random_sample,\n",
    "                                                                     optical_flow=self.optical_flow)))\n",
    "                frame_array.append(frame)\n",
    "                flpts_array.append(flpts)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            flpts_ar = torch.Tensor(np.array(flpts_array))\n",
    "            torch_frames = torch.cat(frame_array,0)\n",
    "            self.optimizer.zero_grad()\n",
    "            net.init_hidden()\n",
    "            if self.optical_flow:\n",
    "                outputs = self.net(torch_frames,flpts_ar)\n",
    "            else:\n",
    "                outputs = self.net(torch_frames)\n",
    "            targets = torch.LongTensor(b_targets)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "#             import pdb; pdb.set_trace()\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            running_loss += loss.detach().numpy()\n",
    "#             import pdb; pdb.set_trace()\n",
    "            correct_i, total_i = self.get_accuracy(outputs, targets)\n",
    "            correct += correct_i\n",
    "            total += total_i\n",
    "#         import pdb; pdb.set_trace()\n",
    "        loss_vec.append(running_loss/(len(labels))/self.batch_size)\n",
    "        acc_vec.append(correct/total)\n",
    "        return loss_vec, acc_vec\n",
    "\n",
    "    def run_epochs(self,save_name):\n",
    "        e_train_loss = []\n",
    "        e_train_acc = []\n",
    "        e_test_loss = []\n",
    "        e_test_acc = []\n",
    "        for i in range(self.epochs):\n",
    "            train_loss, train_acc = self.train_test(self.datapath, train=True)\n",
    "            test_loss, test_acc = self.train_test(self.datapath, train=False)\n",
    "            e_train_loss.append(train_loss)\n",
    "            e_test_loss.append(test_loss)\n",
    "            e_train_acc.append(train_acc)\n",
    "            e_test_acc.append(test_acc)\n",
    "            torch.save(self.net.state_dict(),save_name + '.pt')\n",
    "            torch.save(self.optimizer.state_dict(),save_name + '_opt.pt')\n",
    "            with open(save_name + '_trainloss.csv','a') as f:\n",
    "                f.write(str(train_loss))\n",
    "            with open(save_name + '_trainacc.csv','a') as f:\n",
    "                f.write(str(train_acc))\n",
    "            with open(save_name + '_testloss.csv','a') as f:\n",
    "                f.write(str(test_loss))\n",
    "            with open(save_name + '_testacc.csv','a') as f:\n",
    "                f.write(str(test_acc))\n",
    "            print('Epoch ' + str(i) + ':  Train Loss: ' + str(train_loss) + '; Test Loss: ' + str (test_loss))\n",
    "            print('Epoch ' + str(i) + ':  Train Accuracy: ' + str(train_acc) + '; Test Accuracy: ' + str (test_acc))\n",
    "        return e_train_loss, e_test_loss, e_train_acc, e_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:102: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-1cfb68c10ede>(66)train_test()\n",
      "-> frame = torch.Tensor(np.array(frame))\n",
      "(Pdb) c\n",
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "> /datasets/home/69/969/jdawkins/VideoNet/helper_optflow2.py(51)video3d()\n",
      "-> fin_dummy = np.dot(proj, flow.flatten())\n"
     ]
    }
   ],
   "source": [
    "base_path = 'VideoData/'\n",
    "paths = os.listdir(base_path)\n",
    "paths = [path[2:] for path in paths if path[0]=='.']\n",
    "labels = [re.findall('_([^_]*)_', datastr)[0] for datastr in paths]\n",
    "x = list(set(labels))\n",
    "dic = dict(zip(x, list(range(0,len(x)))))\n",
    "method = 'conv_pool'\n",
    "num_epochs = 50\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "color = False\n",
    "random_sample = False\n",
    "skip = True\n",
    "load = False\n",
    "save_name = 'NEWDATAoptflow_conv_rand_noskip'\n",
    "\n",
    "if color:\n",
    "    input_features = 3\n",
    "else:\n",
    "    input_features = 1\n",
    "\n",
    "if method == 'single':\n",
    "    timesteps_vid = 1\n",
    "    timesteps_net = 1\n",
    "    net = VidNet(method,6,input_features*timesteps_net,timesteps_vid,timesteps_vid,optical_flow=True)\n",
    "elif method=='conv_pool':\n",
    "    timesteps_vid = 16\n",
    "    timesteps_net = 16\n",
    "    net = VidNet(method,6,input_features*timesteps_net,1,timesteps_vid,optical_flow=True)\n",
    "elif method == 'late':\n",
    "    timesteps_vid = 8\n",
    "    timesteps_net = 1\n",
    "    net = VidNet(method,6,input_features*timesteps_net,timesteps_vid,timesteps_vid,optical_flow=True)\n",
    "elif method == 'slow':\n",
    "    timesteps_vid = 16\n",
    "    timesteps_net = 4\n",
    "    net = VidNet(method,6,input_features*timesteps_net,1,timesteps_vid,optical_flow=True)\n",
    "else:\n",
    "    print('define valid method')\n",
    "if load:\n",
    "    net.load_state_dict(torch.load(save_name + '.pt'))\n",
    "    net.cuda()\n",
    "    print(next(net.parameters()).is_cuda)\n",
    "#     for statet in net.state.values():\n",
    "#         for h,g in statet.items():\n",
    "#             if torch.is_tensor(g):\n",
    "#                 statet[h] = g.cuda()\n",
    "    optimize = optim.Adam(net.parameters(), lr = 0.0001, weight_decay = .005)\n",
    "    optimize.load_state_dict(torch.load(save_name + '_opt.pt'))\n",
    "    for state in optimize.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.cuda()\n",
    "else:\n",
    "    optimize = optim.Adam(net.parameters(), lr = 0.0001, weight_decay = .005)\n",
    "#     net.cuda()\n",
    "crit = nn.CrossEntropyLoss()\n",
    "#(self,net,train_path,test_path,vid_path,epochs,optimizer,criterion)\n",
    "tr = Trainer(net,dic,base_path,timesteps_vid,num_epochs,optimize,crit,10,color,\n",
    "                random_sample,skip,optical_flow = True)\n",
    "trl,tstl,tra,tsta = tr.run_epochs(save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'optical_flow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9227cf9071f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m tr = Trainer(net,base_path+'train_clean.txt',base_path+'test_clean.txt',\n\u001b[1;32m     55\u001b[0m                 \u001b[0mvid_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimesteps_vid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 random_sample,skip,optical_flow = True)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mtrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtstl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtra\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtsta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'optical_flow'"
     ]
    }
   ],
   "source": [
    "base_path = 'hollywood/annotations/'\n",
    "vid_path = 'videoclips'\n",
    "method = 'slow'\n",
    "num_epochs = 50\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "color = False\n",
    "random_sample = True\n",
    "skip = True\n",
    "load = True\n",
    "save_name = '_FULLoptflow_slow_norand_skip'\n",
    "\n",
    "if color:\n",
    "    input_features = 3\n",
    "else:\n",
    "    input_features = 1\n",
    "\n",
    "if method == 'single':\n",
    "    timesteps_vid = 1\n",
    "    timesteps_net = 1\n",
    "    net = VidNet(method,6,input_features*timesteps_net,timesteps_vid,timesteps_vid,optical_flow=True)\n",
    "elif method=='conv_pool':\n",
    "    timesteps_vid = 16\n",
    "    timesteps_net = 16\n",
    "    net = VidNet(method,6,input_features*timesteps_net,1,timesteps_vid,optical_flow=True)\n",
    "elif method == 'late':\n",
    "    timesteps_vid = 8\n",
    "    timesteps_net = 1\n",
    "    net = VidNet(method,6,input_features*timesteps_net,timesteps_vid,timesteps_vid,optical_flow=True)\n",
    "elif method == 'slow':\n",
    "    timesteps_vid = 16\n",
    "    timesteps_net = 4\n",
    "    net = VidNet(method,6,input_features*timesteps_net,1,timesteps_vid,optical_flow=True)\n",
    "else:\n",
    "    print('define valid method')\n",
    "if load:\n",
    "    net.load_state_dict(torch.load(save_name + '.pt'))\n",
    "    net.cuda()\n",
    "    print(next(net.parameters()).is_cuda)\n",
    "#     for statet in net.state.values():\n",
    "#         for h,g in statet.items():\n",
    "#             if torch.is_tensor(g):\n",
    "#                 statet[h] = g.cuda()\n",
    "    optimize = optim.Adam(net.parameters(), lr = 0.0001, weight_decay = .005)\n",
    "    optimize.load_state_dict(torch.load(save_name + '_opt.pt'))\n",
    "    for state in optimize.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.cuda()\n",
    "else:\n",
    "    optimize = optim.Adam(net.parameters(), lr = 0.0001, weight_decay = .005)\n",
    "    net.cuda()\n",
    "crit = nn.CrossEntropyLoss()\n",
    "#(self,net,train_path,test_path,vid_path,epochs,optimizer,criterion)\n",
    "tr = Trainer(net,base_path+'train_clean.txt',base_path+'test_clean.txt',\n",
    "                vid_path,timesteps_vid,num_epochs,optimize,crit,10,color,\n",
    "                random_sample,skip,optical_flow = True)\n",
    "trl,tstl,tra,tsta = tr.run_epochs(save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
